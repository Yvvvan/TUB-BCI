{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 4: Neural Mass Models & Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import spatial\n",
    "from scipy import signal\n",
    "\n",
    "def logistic(h,a=1):\n",
    "    return 1/(1+np.exp(-a*h))\n",
    "def dlogistic(h,a=1):\n",
    "    return a*(logistic(h,a)-np.power(logistic(h,a),2))\n",
    "\n",
    "def gaussRBF(h,a=1):\n",
    "    return np.exp(-(a*h)**2)\n",
    "\n",
    "def dgaussRBF(h,a=1):\n",
    "    return -2*a**2*h*np.exp(-(a*h)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code given: Gradient Descent on a single neuron and an MLP\n",
    "The neuron class below from sheet 1 is extended and includes the Gradient Descent training algorithm as a method. It uses the sum of squares error to measure the output error.\n",
    "A method calculating the last local error ($\\delta$) of the neuron and one for training the neuron using the derivative of the ouput error $\\frac{dE}{dy}=y-o$ is included.\n",
    "\n",
    "The train function updates the weights by the gradient descent weight update rule $w(t+1)=w(t)-\\eta\\delta(t)\\cdot x(t)$ and the bias by $b(t+1)=b(t)-\\eta\\delta(t)$ with $\\eta$ being the learning rate. As input arguments it should get the derivative of the output error $\\frac{dE}{dy}=y-o$ and the learning rate.\n",
    "\n",
    "The class \"MLP\" includes a list of layers of type \"MLPlayer\" called \"MLP.layers\" Also, there is a method \"MLP.out(x)\" that returns the outputs of the whole network of the input vector \"x\".\n",
    "\n",
    "The size of the weight vector is set to the number of inputs for the first layer and the number of inputs for the following layers corresponds to the number of neurons in the preceding layer. The number of outputs equals the number of neurons in the last layer.\n",
    "\n",
    "The backpropagation training algorithm is included as a method \"MLP.train()\" into the class. The passed arguments should consist of the number of iterations (no stopping criteria in this case), the training input and the training output - both as function pointers - as well as the learning rate. It iterates over the layers, which themselves iterate over their neurons. Deltas and W of the following layer will allways be the input to the previous.\n",
    "\n",
    "The function pointer argument x_train has to link to a function that produce a random array of inputs of size [NoInputs,] and o_train has to produce the corresponding target function output for a given input. x_train should work without an argument passed and the target training output $o$ should be calculated using only that vector $x$.\n",
    "\n",
    "The output of the method *train()* consists of the sum-of-squares error within each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuron:    \n",
    "    lasth=0\n",
    "    lastout=0\n",
    "    lastin=0\n",
    "    \n",
    "    def __init__(self,w,b,trafunc=logistic,dtrafunc=dlogistic):\n",
    "        self.w=np.array(w)\n",
    "        self.b=np.array(b)\n",
    "        self.trafunc=trafunc\n",
    "        self.dtrafunc=dtrafunc\n",
    "        \n",
    "    def out(self, x):\n",
    "        self.lastin=x;\n",
    "        self.lasth=np.dot(self.w,x)-self.b\n",
    "        self.lastout=self.trafunc(self.lasth)\n",
    "        return self.lastout   \n",
    "    \n",
    "    def delta(self,deltanext,weightsnext):\n",
    "        df=self.dtrafunc(self.lasth)\n",
    "        self.lastdelta=np.dot(deltanext,weightsnext)*df     \n",
    "        return self.lastdelta\n",
    "    \n",
    "    def train(self,deltanext,weightsnext,learnrate=0.1):\n",
    "        self.delta(deltanext,weightsnext)\n",
    "        self.w=self.w-learnrate*self.lastdelta*self.lastin\n",
    "        self.b=self.b+learnrate*self.lastdelta\n",
    "        return self.lastdelta\n",
    "\n",
    "class MLPlayer:\n",
    "    def __init__(self,NodeNo,WeightNo,weightinit=np.random.randn,biasinit=np.random.randn,trafunc=logistic,dtrafunc=dlogistic):\n",
    "        self.nodes=[neuron(weightinit(WeightNo),biasinit(1),trafunc,dtrafunc) for i in range(NodeNo)]\n",
    "    def out(self,x):\n",
    "        return np.ravel([n.out(x) for n in self.nodes])\n",
    "    def train(self,deltanext,W,learnrate=0.1):    \n",
    "        Wo=np.array([n.w for n in self.nodes]).T\n",
    "        deltas=np.array([ n.train(deltanext,W[ineur],learnrate) for ineur,n in enumerate(self.nodes)]).T\n",
    "        return deltas, Wo\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self,InputNo,NodeNos,weightinit=np.random.randn,biasinit=np.random.randn,trafunc=logistic,dtrafunc=dlogistic):        \n",
    "        self.NodeNos=np.append(InputNo,NodeNos)\n",
    "        self.layers=[MLPlayer(self.NodeNos[i+1],self.NodeNos[i],weightinit,biasinit,trafunc,dtrafunc) for i in range(self.NodeNos.size-1)]\n",
    "    def out(self,x):\n",
    "        for i in range(len(self.layers)):\n",
    "            x=self.layers[i].out(x)\n",
    "        self.lastout=x\n",
    "        return x\n",
    "    def train(self,NumIt,x_train,o_train,learnrate=0.1):\n",
    "        errors=np.zeros(NumIt)\n",
    "        for i in range(NumIt):\n",
    "            if callable(x_train):\n",
    "                x=x_train()\n",
    "            else:\n",
    "                x=x_train[i]\n",
    "            if callable(o_train):\n",
    "                o=o_train(x)\n",
    "            else:   \n",
    "                o=o_train[i]                       \n",
    "            y=self.out(x)\n",
    "            if len(y)==1:\n",
    "                o=np.array([o]) \n",
    "                y=np.array([y])\n",
    "            deltas=y-o\n",
    "            W=np.eye(y.shape[0])   \n",
    "            for il, l in enumerate(reversed(self.layers)): \n",
    "                deltas, W=l.train(deltas,W,learnrate)\n",
    "            errors[i]=0.5*np.sum(np.power(y-o,2))       \n",
    "        return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: logical functions (2 points - programming)\n",
    "Train a single neuron on the logical functions below for a two-dimensional input $x$. Use instances of the neuron class above to build the equivalents to logical \"or\",\"and\" and \"xor\"-functions and test them for 2-dimensional input vectors *x* resembling all possibilities of combinations ([0,0] [1,0], [0,1], [1,1]). Do 10.000 iterations and plot the evolution of the error (the error over the iteration number). You don't need to implement a stopping criterion.\n",
    "\n",
    "Set the learning rate to $\\eta=1$ and initialize the weight $w$ and the bias $b$ randomly with normal distribution (np.random.randn). Use the logistic function.\n",
    "\n",
    "In the next cell you find an exemplary random number generator and the corresponding functions you can use for sample creation in every single iteration. In every iteration use the random input $x$, the neuron output *$y=$neuron.out($x$)* and the training data $o=targefunction(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_display(NumIt,neuron1,inputfunc,targetfunc):\n",
    "    errors=np.zeros(NumIt)\n",
    "    for i in range(NumIt):\n",
    "        x=inputfunc()\n",
    "        neuron1.train(neuron1.out(x)-targetfunc(x),1)\n",
    "        errors[i]=0.5*np.sum(np.power(neuron1.out(x)-targetfunc(x),2))\n",
    "    plt.plot(errors)\n",
    "    return neuron1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "peter=lambda :np.random.randint(2,size=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.neuron at 0x1f1b5164e80>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "neuron1=neuron([1,1],1.5)\n",
    "train_and_display(1000,neuron1, peter,lambda x:x[0]+x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 Train an MLP on the XOR (2 points - programming)\n",
    "Train a Multi-Layer-Perceptron on the logical \"xor\"-function. Do the same training on an XOR as in exercise 1, using an architecture of 2 and then 3 neurons in the first layer and one output neuron in the second (you may use the sample solution code). Do 10.000 iterations and plot the evolution of the error. You don't need to implement a stopping criterion. Use the logistic transfer function.\n",
    "\n",
    "Set the learning rate to $\\eta=1$.\n",
    "\n",
    "Investigate the following steps:\n",
    "\n",
    "a) The network should consist of two layers, where the first has the two input neurons and the second only one output neuron. Does it always converge?\n",
    "\n",
    "b) The network should consist of two layers, where the first has the three  input neurons and the second only one output neuron. Does it now always converge?\n",
    "\n",
    "What can we learn from this?\n",
    "\n",
    "The MLP is already implemented above.\n",
    "The syntax of the contained MLP class is:\n",
    "*NeuralNetwork=MLP(NoInputs,ListNoNeuronsPerLayer)*\n",
    "for initialization and \n",
    "*errors=NeuralNetwork.train(NoIterations,x, o ,learnrate)* for training. $x$ and $o$ can either be function pointers as defined or arrays of samples. If they are functions, $x$ has to produce a random array of inputs of size [NoInputs,] and $o(x)$ has to produce the corresponding target function output. If they are samples they have to have the shape *x.shape=[NoIterations,NoInputs]* and *o.shape=[NoIterations,NoOutputs]*.\n",
    "\n",
    "See descriptions above for further explanations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralnet=MLP(2,[2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24220773])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuralnet.out(peter())\n",
    "neuralnet.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: A neural network described by a connectivity matrix (5 points - programming)\n",
    "We will now translate the network described by objects into a connectivity matrix and then iterate over points in time in order to propagate the input to the output.\n",
    "\n",
    "The connectivity is only supposed to be close to instantaneous in this task, we will introduce delay between different areas in the next task. The connectivity is hence a matrix $W$ of size (NoNeurons, NoNeurons).\n",
    "\n",
    "The vector of network state variables $\\mathbf{x}_t$  at time point $t$ shall include the input in the first variables. The new state $\\mathbf{x}_{t+1}$ for the next time step is calculated by:\n",
    "$\\mathbf{x}_{t+1}=f(\\mathbf{h})=f(\\mathbf{W} \\cdot \\mathbf{x}_{t} -\\mathbf{b})$\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "a) Calculate the connectivity matrix $W$ and the bias vector $\\mathbf{b}$ out of the MLP from task 2 b) (if you have not succeeded with training the MLP simply use a feedforward MLP of size (3,1) with arbitrary wiring). To this extent, translate layerwise indexed neurons into a unique index across layers and then connect neurons from each layer only with the preceeding layer/the input, respectively. Print the matrix to command line.\n",
    "\n",
    "b) Simulate a propagation of a random logic vector of size 2 (as in task 2) until it reaches the output layer. This means iteration over time points, where in each time point the output $f(\\mathbf{h})$ from the preceeding time point $t$  is used as the input for the next time point $t+1$. Print the state variables $x_t$ at every step and the output of the network at the end to the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.11016402, -1.06883706])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuralnet.layers[0].nodes[0].w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 : Neural Mass Model (6 points - programming)\n",
    "\n",
    "We will now look at a neural mass model based on the source positions from our head model (gridpos.npy).\n",
    "You will find the connected equations again on the last slides of the current lecture.\n",
    "\n",
    "\n",
    "** Tasks: **\n",
    "\n",
    "a) Derive the distance matrix $\\mathbf{D}$ from the source positions in gridpos using scipy.spatial.distance_matrix(...).\n",
    "\n",
    "b) Calculate the matrix of weights $\\mathbf{W}_0$ with dimensionality (NoSources,NoSources) by distance without delay using the equation $\\mathbf{W}=a_0 e^{b_0\\mathbf{D}}+a_1 e^{b_1\\mathbf{D}}$. Use $a_0=0.03$, $b_0=10$ for replicating excitatory connections and $a_1=-0.25$ and $b_1=50$ for inhibitory. Plot the matrix $\\mathbf{W}_0$ using imshow.\n",
    "\n",
    "c) Calculate the delay $\\Delta t=\\frac{\\mathbf{D}}{c}+\\Delta t_0$ for each connection by using the transmission speed $c=0.5 \\frac{m}{s}$ and the synaptic delay $\\Delta t_0=2ms$ as a matrix corresponding to the dimensions of $\\mathbf{D}$. Then introduce a sampling rate of $fs=100Hz$ and discretize the delay into time samples. Calculate the maximal time delay $T$.\n",
    "\n",
    "d) Combine the results of b) and c) into an array of size (NoSources,NoSources,MaxDelay+1) by expanding $W_0$ into the time domain/delay. We will call this array $W$.\n",
    "\n",
    "e) Simulate the multi-variate time course for a random starting point of the network over $1s$ with $fs=100Hz$ by creating a random array X of size (NoSources,MaxDelay+1) with uniform distribution (np.random.rand) and then propagate activity over time. To this extent, use the current state history array $\\mathbf{X}$ of the network to calculate the source activity vector for the next time step by $\\mathbf{y}=f(\\mathbf{W} \\odot \\mathbf{X})$. $\\odot$ can be calculated using np.tensordot(W,X,axes=2). Then $\\mathbf{X}$ can be shifted like a circular buffer so that the oldest source activity vector is discarded while the newest is set to $\\mathbf{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridpos=np.load('gridpos.npy')\n",
    "fs=1000\n",
    "c=0.5\n",
    "wde=10\n",
    "wdi=50\n",
    "T0=2\n",
    "Nsource=gridpos.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0=[0,0,0]\n",
    "p1=[0,0,1]\n",
    "fs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeltaT=(0.5*spatial.distance_matrix([p0,p1],[p0,p1])+0.002)*fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2., 502.],\n",
       "       [502.,   2.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeltaT"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
